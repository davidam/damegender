* Logo

[[file:files/images/gender.png]]

* Name
damegender is a gender detection tool coded by David Arroyo MEnéndez (DAME)

* Why?
+ If you want determine gender gap in free software projects or mailing lists.
+ If you don't know the gender about a name in spanish or english (current status).
+ If you want research with statistics about why a name is related with males or females.
+ If you want use the main solutions in gender detection (genderize,
  genderapi, namsor, nameapi and gender guesser) from a command.

DAMe Gender is for you!

* Install
** Installing Software
#+BEGIN_SRC sh
$ sudo apt-get install python3-nose-exclude dict dict-freedict-eng-spa dict-freedict-spa-eng dictd
$ git clone https://github.com/davidam/damegender
$ cd damegender
$ pip3 install -r requirements.txt
#+END_SRC
** Obtaining an api key

Currently you can need an api key from:
+ https://store.genderize.io/documentation
+ https://gender-api.com
+ https://www.nameapi.org/

You can execute:
#+BEGIN_SRC
$ python3 apikeyadd.py
#+END_SRC
To configure your api key

** Configuring nltk

#+BEGIN_SRC sh
$ python3
>>> import nltk
>>> nltk.download('names')
#+END_SRC

* Check test
** All tests
#+BEGIN_SRC sh
$ nosetest3 test
#+END_SRC
** Single test
#+BEGIN_SRC sh
$ nosetests3 test/test_dame_sexmachine.py:TddInPythonExample.test_string2array_method_returns_correct_result
#+END_SRC
* Execute program

#+BEGIN_SRC sh
# Detect gender from a name (INE is the dataset used by default)
$ python3 main.py David
David gender is male
363559  males for David from INE.es
0 females for David from INE.es

# Detect gender from a name from multiple dataset
$ python3 main.py David --total="all"
David gender is male
375099 males and 9 females from all census (INE + Uk census + USA census)

# Detect gender from a name only using machine learning (experimental way)
$ python3 main.py Mesa --ml=nltk
Mesa gender is female
0 males for Mesa from INE.es
0 females for Mesa from INE.es

# Count gender from a git repository
$ python3 git2gender.py https://github.com/chaoss/grimoirelab-perceval.git --directory="/tmp/clonedir"
The number of males sending commits is 15
The number of females sending commits is 7

# Count gender from a mailing list
$ cd files/mbox
$ wget -c http://mail-archives.apache.org/mod_mbox/httpd-announce/201706.mbox
$ cd ..
$ python3 mail2gender.py http://mail-archives.apache.org/mod_mbox/httpd-announce/

# Use an api to detect the gender
$ python3 api2gender.py Leticia --surname="Martin" --api=namsor
female
scale: 0.99

# Google popularity for a name
$ python3 gendergoogle.py Leticia
Google results of Leticia as male: 42300
Google results of Leticia as female: 63400

# Give me informative features
$ python3 infofeatures.py
Females with last letter a: 0.4705246078961601
Males with last letter a: 0.048672566371681415
Females with last letter consonant: 0.2735841767750908
Males with last letter consonant: 0.6355328972681801
Females with last letter vocal: 0.7262612995441552
Males with last letter vocal: 0.3640823393612928

# To measure success
$ python3 accuracy.py --csv=files/names/min.csv
################### NLTK!!
Gender list: [1, 1, 1, 1, 2, 1, 0, 0]
Guess list:  [1, 1, 1, 1, 0, 1, 0, 0]
Dame Gender accuracy: 0.875

$ python3 accuracy.py --api="genderize" --csv=files/names/min.csv
################### Genderize!!
Gender list: [1, 1, 1, 1, 2, 1, 0, 0]
Guess list:  [1, 1, 1, 1, 2, 1, 0, 0]
Genderize accuracy: 1

$ python3 confusion.py
A confusion matrix C is such that Ci,j is equal to the number of observations known to be in group i but predicted to be in group j.
If the classifier is nice, the diagonal is high because there are true positives
Namsor confusion matrix:
 [[2 0 0]
 [0 5 0]
 [0 1 0]]
Genderize confusion matrix:
 [[2 0 0]
 [0 5 0]
 [0 0 1]]
Gender Guesser confusion matrix:
 [[2 0 0]
 [0 5 0]
 [0 1 0]]
Sexmachine confusion matrix:
 [[2 0 0]
 [0 5 0]
 [1 0 0]]
Nameapi confusion matrix:
 [[0 0 2]
 [0 0 5]
 [0 0 1]]

# To analyze errors guessing names from a csv
$ python3 errors.py --csv="files/names/all.csv" --api="genderguesser"
Gender Guesser with files/names/all.csv has:
+ The error code: 0.22564457518601835
+ The error code without na: 0.026539047204698716
+ The na coded: 0.20453365634192766
+ The error gender bias: 0.0026103980857080703

# To deploy a graph about correlation between variables
$ python3 corr.py
$ python3 corr.py --csv="categorical"
$ python3 corr.py --csv="nocategorical"
# To create the pickle models in files directory
$ python3 damemodels.py
# Experiments to determine features with weight (not finished)
$ python3 pca-components.py --csv="files/features_list.csv" # To determine number of components
$ python3 pca-features.py                                   # To understand the weight between variables for a target
#+END_SRC
* Benchmarking
** Market Study

|                                        | damegender      | gender api        | gender guesser | genderize               | name api                    | namsor                    |
| Database size                          | 60000           | 1877787           | 45376          | 216286                  | 510000                      | 1300000                   |
| Regular data updates                   | yes, developing | yes               | no             | yes                     | yes                         | yes                       |
| Handles unstructured full name strings | yes             | yes               | no             | no                      | yes                         | no                        |
| Handles surnames                       | yes             | yes               | no             | no                      | yes                         | yes                       |
| Handles non-Latin alphabets            | no              | partially         | no             | partially               | yes                         | yes                       |
| Implicit geo-localization              | no              | no                | no             | no                      | yes                         | yes                       |
| Assingment type                        | binary          | probabilistic     | binary         | probabilistic           | probabilistic               | probabilistic             |
| Free parameters                        | -               | accuracy, samples | -              | probability             | confidence                  | scale                     |
| Free license                           | yes             | no                | yes            | no                      | no                          | no                        |
| API                                    | future          | yes               | no             | yes                     | yes                         | yes                       |
| Monthly free requests                  | free license    | 500               | free license   | Free for 1000 names/day | Free for 1000 credits/month | Free for 5000 names/month |

** Accuracy

|                |           Accuracy |
| Namsor         | 0.7539570378745054 |
| Genderize      | 0.715375918598078  |
| Gender Guesser | 0.6902204635387225 |
| Dame Gender    | 0.6677501413227812 |

Dame Gender is only supporting names in english and spanish. We hope
better results with more languages.

** Confusion Matrix

**** Genderguesser
#+BEGIN_SRC sh
 [[ 1686, 78, 204]
 [ 139, 3326, 346]]
#+END_SRC

**** Genderize
#+BEGIN_SRC sh
[[ 1742, 75, 151]
 [ 242, 3157, 412]]
#+END_SRC
**** Namsor
#+BEGIN_SRC sh
[[ 1686, 78, 204]
 [ 139, 3326, 346]]
#+END_SRC
**** Nameapi
#+BEGIN_SRC sh
[[ 3126, 93, 592]
 [75, 1616, 277]]
#+END_SRC
**** Dame Gender
#+BEGIN_SRC sh
 [[ 1692, 276, 0]
 [ 778, 3033, 0]]
#+END_SRC

In this version of Dame Gender, we are not considering decide names as undefined.

** Errors with files/names/all.csv has:
*** Gender Guesser

| The error code            |  0.22564457518601835 |
| The error code without na | 0.026962383126766687 |
| The na coded              |   0.2041875757051393 |
| The error gender bias     |   0.0030441400304414 |

The command was:

#+BEGIN_SRC
$ python3 errors.py --api="genderguesser" --csv="files/names/all.csv"
#+END_SRC

*** Damegender

| The error code            | 0.18238449558747188 |
| The error code without na | 0.18238449558747188 |
| The na coded              |                 0.0 |
| The error gender bias     |  0.0868662398338813 |

The command was:

#+BEGIN_SRC
$ python3 errors.py --api="damegender" --csv="files/names/all.csv"
#+END_SRC

*** Namsor

#+BEGIN_SRC
$ python3 errors.py --api="namsor" --csv="files/names/all.csv"
Namsor with files/names/all.csv has:
#+END_SRC

| The error code            |  0.13272192420834053 |
| The error code without na | 0.041499330655957165 |
| The na coded              |  0.09517217511680222 |
| The error gender bias     | 0.011665710460891184 |


* Statistics for damegender
Some theory could be useful to understand some commands
** Errors and Confusion Matrix
Guessing the sex, we have an true idea (example: female) and we obtain
a result, the guessed result (example: female). We have written
count_true2guess to make statistics variables about it.

In confusion matrix litherature, we can find this vocabulary for true and guess:

| True positive  | False Positive |
|----------------+----------------|
| False negative | True Negative  |

*Precision* is about true positives between true positives plus false positives

#+BEGIN_SRC
(self.femalefemale + self.malemale ) / (self.femalefemale + self.malemale + self.femalemale)
#+END_SRC

*Recall* is about true positives between true positives plus false negatives.

#+BEGIN_SRC
(self.femalefemale + self.malemale ) / (self.femalefemale + self.malemale + self.malefemale)
#+END_SRC

The *F1 score* is the harmonic mean of precision and recall taking
both metrics into account in the following equation:

#+BEGIN_SRC
2 * ((precision * recall) / (precision + recall))
#+END_SRC

*Error coded* is about the true is different than the guessed:

#+BEGIN_SRC
(self.femalemale + self.malefemale + self.maleundefined + self.femaleundefined) / (self.malemale + self.femalemale + self.malefemale + self.femalefemale + self.maleundefined + self.femaleundefined)
#+END_SRC

*Error coded without na* is about the true is different than the guessed, but without undefined results.

#+BEGIN_SRC
(self.maleundefined + self.femaleundefined) / (self.malemale + self.femalemale + self.malefemale + self.femalefemale + self.maleundefined + self.femaleundefined)
#+END_SRC

*Error gender bias* is to understand if the error is bigger guessing males than females or viceversa.

#+BEGIN_SRC
(self.malefemale - self.femalemale) / (self.malemale + self.femalemale + self.malefemale + self.femalefemale)
#+END_SRC

*The weighted error* is about the true is different than the guessed, but giving a weight to the guessed as undefined.

#+BEGIN_SRC
(self.femalemale + self.malefemale + w * (self.maleundefined + self.femaleundefined)) / (self.malemale + self.femalemale + self.malefemale + self.femalefemale + w * (self.maleundefined + self.femaleundefined))
#+END_SRC

The *confusion matrix* creates a matrix between the true and the guess. If you have this confusion matrix:

#+BEGIN_SRC
[[ 2, 0, 0]
 [ 0, 5, 0]]
#+END_SRC
It means, I have 2 females true and I've guessed 2 females and I've 5 males true and I've guessed 5 males. I don't have errors in my classifier.

#+BEGIN_SRC
 [[ 2  1  0]
 [ 2 14  0]
#+END_SRC

It means, I have 2 females true and I've guessed 2 females and I've 14 males true and I've guessed 14 males. 1 female was considered male, 2 males was considered female.

** PCA
*** Concepts
The dispersion measures between 1 variables are: variance, standard
deviation, ...

[[file:files/images/variance.png]]

If you have 2 variables, you can write a formula so similar to variance.

[[file:files/images/covariance.png]]

If you have 3 variables or more, you can write a covariance matrix.

[[file:files/images/matrix-covariance.png]]

In essence, an eigenvector v of a linear transformation T is a
non-zero vector that, when T is applied to it, does not change
direction. Applying T to the eigenvector only scales the eigenvector
by the scalar value λ, called an eigenvalue.

[[file:files/images/eigenvector.png]]

A feature vector is constructed taking the eigenvectors that you want
to keep from the list of eigenvectors.

The new dataset take the transpose of the vector and multiply it on
the left of the original data set, transposed.

#+BEGIN_SRC
FinalData = RowFeatureVector x RowDataAdjust
#+END_SRC

We can choose PCA using the covariance method as opposed to the
correlation method.

The [[https://en.wikipedia.org/wiki/Principal_component_analysis#Computing_PCA_using_the_covariance_method][covariance method]] has the next steps:
1. Organize the data set
2. Calculate the empirical mean
3. Calculate the deviations from the mean
4. Find the covariance matrix
5. Find the eigenvectors and eigenvalues of the covariance matrix
6. Rearrange the eigenvectors and eigenvalues
7. Compute the cumulative energy content for each eigenvector
8. Select a subset of the eigenvectors as basis vectors
9. Project the z-scores of the data onto the new basis

The [[https://www.itl.nist.gov/div898/handbook/pmc/section5/pmc552.htm][correlation method]] has the next steps:
1. Compute the correlation matrix
2. Solve for the correlation roots of R (product of eigenvalues)
3. Compute the first column of the V matrix
4. Compute the remaining columns of the V matrix
5. Compute the L^(1/2) matrix
6. Compute the communality
7. Diagonal elements report how much of the variability is explained
8. Compute the coefficient matrix
9. Compute the principal factors

*** Choosing components

We can choose components with:

#+BEGIN_SRC
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('--csv')
args = parser.parse_args()

#filepath = 'files/features_list.csv' #your path here
data = np.genfromtxt(args.csv, delimiter=',', dtype='float64')

scaler = MinMaxScaler(feature_range=[0, 1])
data_rescaled = scaler.fit_transform(data[1:, 0:8])

#Fitting the PCA algorithm with our Data
pca = PCA().fit(data_rescaled)
#Plotting the Cumulative Summation of the Explained Variance
plt.figure()
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Variance (%)') #for each component
plt.title('Dataset Explained Variance')
plt.show()
#+END_SRC

[[file:files/images/pca-number-components.png]]

Taking a look to the image. We can choose 6 components.

*** Load Dataset

We choose the file all.csv to generate features and a list to determine gender (male or female)

#+BEGIN_SRC lisp
from pprint import pprint
import pandas as pd
import matplotlib.pyplot as plt
from app.dame_sexmachine import DameSexmachine
from app.dame_gender import Gender

## LOAD DATASET
g = Gender()
g.features_list2csv(categorical="both", path="files/names/all.csv")
features = "files/features_list.csv"

print("STEP1: N COMPONENTS + 1 TARGET")

x = pd.read_csv(features)
print(x.columns)

y = g.dataset2genderlist(dataset="files/names/all.csv")
print(y)
#+END_SRC

*** Standarize the data

#+BEGIN_SRC
print("STEP2: STANDARIZE THE DATA")
from sklearn.preprocessing import StandardScaler
# Standardizing the features
x = StandardScaler().fit_transform(x)
#+END_SRC

*** Pca Projection to N Dimensions

Finally, we create the pca transform with 6 dimensions and we add the target component.

#+BEGIN_SRC
from sklearn.decomposition import PCA
pca = PCA(n_components=6)
principalComponents = pca.fit_transform(x)
print("STEP3: PCA PROJECTION")
pprint(principalComponents)
principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4', 'principal component 5', 'principal component 6'])

target = pd.DataFrame(data = y, columns = ['target component'])

print(principalDf.join(target))
#+END_SRC
